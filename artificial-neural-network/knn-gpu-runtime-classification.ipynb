{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.utils import to_categorical\nfrom sklearn.model_selection import StratifiedKFold,train_test_split, cross_val_score, GridSearchCV, learning_curve, KFold\nfrom sklearn.preprocessing import MinMaxScaler, OneHotEncoder, StandardScaler\nfrom sklearn.metrics import make_scorer, accuracy_score\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.metrics import roc_curve,roc_auc_score, precision_score, recall_score,f1_score\nimport pandas as pd\nimport numpy as np\nimport time\n\nimport matplotlib.pyplot as plt\nfrom sklearn import metrics\nimport seaborn as sns\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data=pd.read_csv(\"../input/sgemm/sgemm_product.csv\")\ndata.head()\n#take average of 4 run\ndata[\"run_avg\"]=np.mean(data.iloc[:,14:18],axis=1)\n\nmean_run=np.mean(data[\"run_avg\"])\nprint(mean_run)\n\n#Binary Classification run_avg>mean_run\ndata[\"run_class\"]=np.where(data['run_avg']>=mean_run, 1, 0)\ndata.groupby(\"run_class\").size()\n\ndata.describe()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Drop unwanted fields\nsgemm_df=data.drop(columns=['Run1 (ms)','Run2 (ms)','Run3 (ms)','Run4 (ms)','run_avg'])\nsgemm_df.to_csv(r'segmm_product_classification.csv')\nsgemm_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#data info\nsgemm_df.info()\n#No null values in the data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#checking for NULL values\nsgemm_df.isnull().sum() #no NULL values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndf_test=sgemm_df.iloc[:,0:14]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#checking variable distribution\nfor index in range(10):\n    df_test.iloc[:,index] = (df_test.iloc[:,index]-df_test.iloc[:,index].mean()) / df_test.iloc[:,index].std();\ndf_test.hist(figsize= (14,16));","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(14,14))\nsns.set(font_scale=1)\nsns.heatmap(df_test.corr(),cmap='GnBu_r',annot=True, square = True ,linewidths=.5);\nplt.title('Variable Correlation')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Varibale and predictor\ny=np.array(sgemm_df[\"run_class\"])\n\nX=np.array(sgemm_df.iloc[:,0:14])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Train Test Validation Split\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n\n\n#X_train, X_val, y_train, y_val = train_test_split(X_train_80, y_train_80, test_size=0.2, random_state=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\n\nk_range= range(1,26)\nscores={}\nscores_list=[]\nfor k in k_range:\n    knn=KNeighborsClassifier(n_neighbors=k)\n    knn.fit(X_train,y_train)\n    y_pred=knn.predict(X_test)\n    scores[k]=metrics.accuracy_score(y_test,y_pred)\n    scores_list.append(scores[k])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#plot relationship between K and the testing accuracy\nplt.plot(k_range,scores_list)\nplt.xlabel('Value of K')\nplt.ylabel('Testing Accuracy')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"knn=KNeighborsClassifier(n_neighbors=5)\nknn.fit(X_train,y_train)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred=knn.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# accuracy: (tp + tn) / (p + n)\naccuracy = accuracy_score(y_test, y_pred)\nprint('Accuracy: %f' % accuracy)\n# precision tp / (tp + fp)\nprecision = precision_score(y_test, y_pred)\nprint('Precision: %f' % precision)\n# recall: tp / (tp + fn)\nrecall = recall_score(y_test, y_pred)\nprint('Recall: %f' % recall)\n# f1: 2 tp / (2 tp + fp + fn)\nf1 = f1_score(y_test, y_pred)\nprint('F1 score: %f' % f1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.model_selection import KFold\n\n\nscores = []\nn=10\ni=0\nmean_auc=0\naccuracy_test=0\naccuracy_train=0\ncv = KFold(n_splits=n, random_state=42, shuffle=True)\nknn=KNeighborsClassifier(n_neighbors=5)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfor train_index, test_index in cv.split(X_train):\n    X_train_cv, X_test_cv= X_train[train_index], X_train[test_index]\n    y_train_cv, y_test_cv = y_train[train_index], y_train[test_index]\n    \n    #Fit Model\n    knn.fit(X_train,y_train)\n\n    #predict train\n    preds_train = knn.predict(X_train_cv)\n\n    #predict test\n    preds_test = knn.predict(X_test_cv)\n    \n    i+=1\n    # compute AUC metric for this CV fold\n    fpr, tpr, thresholds = metrics.roc_curve(y_test_cv, preds_test)\n    roc_auc = metrics.auc(fpr, tpr)\n    print (\"AUC (fold \"+str(i)+\"/\"+str(n)+\"): \"+str(roc_auc))\n    mean_auc += roc_auc\n    \n    print(\"Accuracy Validation Fold \"+str(i)+\" : \"+str(metrics.accuracy_score(y_test_cv,preds_test)*100))\n    accuracy_test+=metrics.accuracy_score(y_test_cv,preds_test)*100\n    print(\"Accuracy Train Fold \"+str(i)+\" : \"+str(metrics.accuracy_score(y_train_cv,preds_train)*100))\n    accuracy_train+=metrics.accuracy_score(y_train_cv,preds_train)*100\n    print(\" \")\n    \nprint (\"Mean AUC: \"+str(mean_auc/n) )\nprint (\"Mean Validation Accuracy: \"+str(accuracy_test/n))\nprint (\"Mean Train Accuracy: \"+str(accuracy_train/n))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = knn.predict(X_test)\nprint(confusion_matrix(y_test,y_pred))\nprint(classification_report(y_test,y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##from sklearn.model_selection import kfold\n#from sklearn.svm import SVC\nfrom sklearn.model_selection import learning_curve\n#cv = ShuffleSplit(n_splits=5, test_size=0.3, random_state=0)\ntrain_sizes, train_scores, test_scores = learning_curve(knn, \n                                                        X_train, \n                                                        y_train,\n                                                        # Number of folds in cross-validation\n                                                        cv=cv,\n                                                        # Evaluation metric\n                                                        scoring='accuracy',\n                                                        # Use all computer cores\n                                                        n_jobs=-1, \n                                                        # 50 different sizes of the training set\n                                                        train_sizes=np.linspace(0.01, 1.0, 50))\n\n# Create means and standard deviations of training set scores\ntrain_mean = np.mean(train_scores, axis=1)\ntrain_std = np.std(train_scores, axis=1)\n\n# Create means and standard deviations of test set scores\ntest_mean = np.mean(test_scores, axis=1)\ntest_std = np.std(test_scores, axis=1)\n\n# Draw lines\nplt.plot(train_sizes, train_mean, '--', color=\"#111111\",  label=\"Training score\")\nplt.plot(train_sizes, test_mean, color=\"#111111\", label=\"Cross-validation score\")\n\n# Draw bands\nplt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, color=\"#DDDDDD\")\nplt.fill_between(train_sizes, test_mean - test_std, test_mean + test_std, color=\"#DDDDDD\")\n\n# Create plot\nplt.title(\"Learning Curve\")\nplt.xlabel(\"Training Set Size\"), plt.ylabel(\"Accuracy Score\"), plt.legend(loc=\"best\")\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}