{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.utils import to_categorical\nfrom sklearn.model_selection import StratifiedKFold,train_test_split, cross_val_score, GridSearchCV, learning_curve, KFold\nfrom sklearn.preprocessing import MinMaxScaler, OneHotEncoder, StandardScaler\nfrom sklearn.metrics import make_scorer, accuracy_score\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.metrics import roc_curve,roc_auc_score, precision_score, recall_score,f1_score\nimport pandas as pd\nimport numpy as np\nimport time\n\nimport matplotlib.pyplot as plt\nfrom sklearn import metrics\nimport seaborn as sns\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data=pd.read_csv(\"../input/sgemm/sgemm_product.csv\")\ndata.head()\n#take average of 4 run\ndata[\"run_avg\"]=np.mean(data.iloc[:,14:18],axis=1)\n\nmean_run=np.mean(data[\"run_avg\"])\nprint(mean_run)\n\n#Binary Classification run_avg>mean_run\ndata[\"run_class\"]=np.where(data['run_avg']>=mean_run, 1, 0)\ndata.groupby(\"run_class\").size()\n\ndata.describe()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Drop unwanted fields\nsgemm_df=data.drop(columns=['Run1 (ms)','Run2 (ms)','Run3 (ms)','Run4 (ms)','run_avg'])\nsgemm_df.to_csv(r'segmm_product_classification.csv')\nsgemm_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#data info\nsgemm_df.info()\n#No null values in the data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#checking for NULL values\nsgemm_df.isnull().sum() #no NULL values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndf_test=sgemm_df.iloc[:,0:14]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#checking variable distribution\nfor index in range(10):\n    df_test.iloc[:,index] = (df_test.iloc[:,index]-df_test.iloc[:,index].mean()) / df_test.iloc[:,index].std();\ndf_test.hist(figsize= (14,16));","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(14,14))\nsns.set(font_scale=1)\nsns.heatmap(df_test.corr(),cmap='GnBu_r',annot=True, square = True ,linewidths=.5);\nplt.title('Variable Correlation')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Varibale and predictor\ny=np.array(sgemm_df[\"run_class\"])\n\nX=np.array(sgemm_df.iloc[:,0:14])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Train Test Validation Split\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n\n\n#X_train, X_val, y_train, y_val = train_test_split(X_train_80, y_train_80, test_size=0.2, random_state=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train_enc = to_categorical(y_train)\ny_test_enc = to_categorical(y_test)\nprint(y_train_enc.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sc = StandardScaler()\nX_train_scaled = sc.fit_transform(X_train)\nX_test_scaled = sc.fit_transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# define the model\n#get number of columns in training data\nn_cols=X_train.shape[1]\n\n# define model 2 layers\nmodel = Sequential()\nmodel.add(Dense(100, input_dim=n_cols, activation='relu'))\nmodel.add(Dense(2, activation='sigmoid'))\n# compile model\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"epochs= 300\nstart=time.time()\n#fit model\nhist=model.fit(X_train_scaled, y_train_enc,  validation_split=0.2, epochs=epochs,batch_size=100, verbose=1)\nend=time.time()\nprint(\"Elapsed Time: \", end-start)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# predict probabilities for test set\nyhat_probs = model.predict(X_test_scaled, verbose=0)\n# predict crisp classes for test set\nyhat_classes = model.predict_classes(X_test_scaled, verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# accuracy: (tp + tn) / (p + n)\naccuracy = accuracy_score(y_test, yhat_classes)\nprint('Accuracy: %f' % accuracy)\n# precision tp / (tp + fp)\nprecision = precision_score(y_test, yhat_classes)\nprint('Precision: %f' % precision)\n# recall: tp / (tp + fn)\nrecall = recall_score(y_test, yhat_classes)\nprint('Recall: %f' % recall)\n# f1: 2 tp / (2 tp + fp + fn)\nf1 = f1_score(y_test, yhat_classes)\nprint('F1 score: %f' % f1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ROC AUC\nauc = roc_auc_score(y_test_enc, yhat_probs)\nprint('ROC AUC: %f' % auc)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# confusion matrix\nmatrix = confusion_matrix(y_test, yhat_classes)\nprint(matrix)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# evaluate the model\n_, train_acc = model.evaluate(X_train_scaled, y_train_enc, verbose=0)\n_, test_acc = model.evaluate(X_test_scaled, y_test_enc, verbose=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot loss during training\nplt.figure(1, figsize=(10,12))\nplt.subplot(211)\nplt.title('Loss')\nplt.plot(hist.history['loss'], label='Train')\nplt.plot(hist.history['val_loss'], label='Validation')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend()\n# plot accuracy during training\nplt.subplot(212)\nplt.title('Accuracy')\nplt.plot(hist.history['accuracy'], label='Train')\nplt.plot(hist.history['val_accuracy'], label='Validation')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Add Additional Layer","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# define the model\n#get number of columns in training data\nn_cols=X_train.shape[1]\n\n# define model 2 layers\nmodel = Sequential()\nmodel.add(Dense(100, input_dim=n_cols, activation='relu'))\nmodel.add(Dense(50,  activation='relu'))\nmodel.add(Dense(2, activation='sigmoid'))\n# compile model\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"epochs= 200\nstart=time.time()\n#fit model\nhist=model.fit(X_train_scaled, y_train_enc,  validation_split=0.2, epochs=epochs,batch_size=100, verbose=1)\nend=time.time()\nprint(\"Elapsed Time: \", end-start)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# predict probabilities for test set\nyhat_probs = model.predict(X_test_scaled, verbose=0)\n# predict crisp classes for test set\nyhat_classes = model.predict_classes(X_test_scaled, verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# accuracy: (tp + tn) / (p + n)\naccuracy = accuracy_score(y_test, yhat_classes)\nprint('Accuracy: %f' % accuracy)\n# precision tp / (tp + fp)\nprecision = precision_score(y_test, yhat_classes)\nprint('Precision: %f' % precision)\n# recall: tp / (tp + fn)\nrecall = recall_score(y_test, yhat_classes)\nprint('Recall: %f' % recall)\n# f1: 2 tp / (2 tp + fp + fn)\nf1 = f1_score(y_test, yhat_classes)\nprint('F1 score: %f' % f1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ROC AUC\nauc = roc_auc_score(y_test_enc, yhat_probs)\nprint('ROC AUC: %f' % auc)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# confusion matrix\nmatrix = confusion_matrix(y_test, yhat_classes)\nprint(matrix)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot loss during training\nplt.figure(1, figsize=(10,12))\nplt.subplot(211)\nplt.title('Loss')\nplt.plot(hist.history['loss'], label='Train')\nplt.plot(hist.history['val_loss'], label='Validation')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend()\n# plot accuracy during training\nplt.subplot(212)\nplt.title('Accuracy')\nplt.plot(hist.history['accuracy'], label='Train')\nplt.plot(hist.history['val_accuracy'], label='Validation')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}